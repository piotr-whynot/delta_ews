{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e155dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,glob\n",
    "os.environ['PROJ_LIB'] = '/home/piotr/anaconda3/lib/python3.8/site-packages/rasterio/proj_data/'\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "from geocube.api.core import make_geocube\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "from PIL import Image\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b780df",
   "metadata": {},
   "source": [
    "# Processing MODIS, CHIRPS and observed data to format used by forecasting fuctions\n",
    "- extracts time series of inundation for each unit\n",
    "- extracts time series of rainfall for each unit\n",
    "- converts daily observations to monthly data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf76635",
   "metadata": {},
   "source": [
    "### rainfall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fe0b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading units file ../data/gis/delta_units_v7.shp\n",
      "done\n",
      "reading rainfall file ../data/rainfall/pr_mon_CHG_CHIRPS-2.0-0p25-prelim_merged_okavango.nc\n",
      "done\n",
      "extracting rainfall for units...\n",
      "done\n",
      "writing rainfall file ../data/rainfall/pr_deltaunits.csv\n",
      "done\n",
      "extracting rainfall for upper catchment...\n",
      "done\n",
      "writing headwaters rainfall file ../data/rainfall/pr_headwaters.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "unitsfilepath=\"../data/gis/delta_units_v7.shp\"\n",
    "rainfallfilepath=\"../data/rainfall/pr_mon_CHG_CHIRPS-2.0-0p25-prelim_merged_okavango.nc\"\n",
    "floodfilepath=\"../data/flood/flood_modis_merged.nc\"\n",
    "\n",
    "#these are output files\n",
    "rainfall4unitsfilepath=\"../data/rainfall/pr_deltaunits.csv\"\n",
    "rainfallheadwatersfilepath=\"../data/rainfall/pr_headwaters.csv\"\n",
    "flood4unitsfilepath=\"../data/flood/flood_deltaunits.csv\"\n",
    "verbose=False\n",
    "\n",
    "###############################################################################################################\n",
    "print(\"reading units file {}\".format(unitsfilepath))\n",
    "\n",
    "if not os.path.exists(unitsfilepath):\n",
    "    print(\"Units file {} does not exist. Exiting...\".format(unitsfilepath))\n",
    "    sys.exit()\n",
    "\n",
    "units = geopandas.read_file(unitsfilepath)\n",
    "print(\"done\")\n",
    "\n",
    "print(\"reading rainfall file {}\".format(rainfallfilepath))\n",
    "\n",
    "if not os.path.exists(rainfallfilepath):\n",
    "    print(\"Rainfall file {} does not exist. Exiting...\".format(rainfallfilepath))\n",
    "    sys.exit()\n",
    "print(\"done\")\n",
    "\n",
    "#processing rainfall\n",
    "data=xr.open_dataset(rainfallfilepath,chunks={'time': 20})\n",
    "pr=data.pr\n",
    "data.close()\n",
    "pr=pr.rio.write_crs(\"epsg:4326\")\n",
    "\n",
    "if verbose:\n",
    "    fig=plt.figure(figsize=(6,8))\n",
    "    pl=fig.add_subplot(1,1,1)\n",
    "    m=(pr.mean(\"time\")*12).sel(latitude=slice(-21,-18), longitude=slice(21,24.5)).plot(add_colorbar=False, cmap=plt.cm.BrBG)\n",
    "    units.plot(ax=pl, alpha=0.3, edgecolor='black', color=\"white\", linewidth=1)\n",
    "    plt.colorbar(m, shrink=0.5)\n",
    "    pl.set_title(\"mean annual rainfall [mm/year]\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"extracting rainfall for units...\")\n",
    "subprpd=pd.DataFrame()\n",
    "for unit in range(8):\n",
    "    if verbose:\n",
    "        print(unit)\n",
    "    subpr=pr.rio.clip(units.geometry.values[unit:(unit+1)], \"epsg:4326\")\n",
    "    subpr=subpr.mean((\"latitude\",\"longitude\")).to_pandas()\n",
    "    subpr.name=units[\"NAME\"][unit]\n",
    "    subprpd=pd.concat([subprpd,subpr], axis=1)\n",
    "subprpd.index=pd.to_datetime([datetime.date(x) for x in subprpd.index])\n",
    "print(\"done\")\n",
    "print(\"writing rainfall file {}\".format(rainfall4unitsfilepath))\n",
    "np.round(subprpd,2).to_csv(rainfall4unitsfilepath)\n",
    "print(\"done\")\n",
    "\n",
    "print(\"extracting rainfall for upper catchment...\")\n",
    "hwtrpr=pr.sel(latitude=slice(-15,-12.5),longitude=slice(16,20)).mean((\"latitude\",\"longitude\"))\n",
    "hwtrpr=pd.DataFrame(hwtrpr.to_pandas(), columns=[\"pr\"])\n",
    "print(\"done\")\n",
    "\n",
    "print(\"writing headwaters rainfall file {}\".format(rainfallheadwatersfilepath))\n",
    "np.round(hwtrpr,2).to_csv(rainfallheadwatersfilepath)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f460f",
   "metadata": {},
   "source": [
    "### flood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe2cf16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading flood file ../data/flood/flood_modis_merged.nc\n",
      "done\n",
      "processing flood\n",
      "done\n",
      "writing flood file ../data/flood/flood_deltaunits.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"reading flood file {}\".format(floodfilepath))\n",
    "\n",
    "if not os.path.exists(floodfilepath):\n",
    "    print(\"Flood file {} does not exist. Run Download notebook. Exiting...\".format(floodfilepath))\n",
    "    sys.exit()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "data=xr.open_dataset(floodfilepath,chunks={'time': 10})\n",
    "flood=data.flood\n",
    "data.close()\n",
    "flood=flood.rio.write_crs(\"epsg:4326\")\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "print(\"processing flood\")\n",
    "#inundation map\n",
    "#clip to units\n",
    "flood=flood.rio.clip(units.geometry, \"epsg:4326\")\n",
    "\n",
    "#this only picks up maps that have few non-classified\n",
    "nans=(flood==2).sum((\"latitude\",\"longitude\"))\n",
    "sel=nans<500\n",
    "flood=flood[sel.values,:,:]\n",
    "\n",
    "if verbose:\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    pl=fig.add_subplot(1,1,1)\n",
    "    m=flood.sum(\"time\").plot(cmap=plt.cm.Blues, ax=pl,add_colorbar=False)\n",
    "    units.plot(ax=pl, alpha=0.5, edgecolor='black', color=\"yellow\",linewidth=1)\n",
    "    plt.colorbar(m, shrink=0.5)\n",
    "    pl.set_title(\"Inundation (# of images) \\nMODIS\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "subfloodpd=pd.DataFrame()\n",
    "for unit in range(8):\n",
    "    if verbose:\n",
    "        print(unit)\n",
    "    subflood=flood.rio.clip(units.geometry.values[unit:(unit+1)], \"epsg:4326\")\n",
    "    subflood=(subflood.sum((\"latitude\",\"longitude\"))/4).to_pandas()\n",
    "    subflood.name=units[\"NAME\"][unit]\n",
    "    subfloodpd=pd.concat([subfloodpd,subflood], axis=1)\n",
    "print(\"done\")\n",
    "\n",
    "print(\"writing flood file {}\".format(flood4unitsfilepath))\n",
    "subfloodpd.to_csv(flood4unitsfilepath)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6b285",
   "metadata": {},
   "source": [
    "### gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "803fe095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "processing toteng\n",
      "reading ../data/gauge//toteng_dly_combined.csv\n",
      "done\n",
      "filtering data\n",
      "done\n",
      "writing filled daily file ../data/gauge//toteng_dly_filled.csv\n",
      "done\n",
      "generating monthly data...\n",
      "done\n",
      "writing monthly file ../data/gauge//toteng_mon.csv\n",
      "done\n",
      "\n",
      "\n",
      "processing maun\n",
      "reading ../data/gauge//maun_dly_combined.csv\n",
      "done\n",
      "filtering data\n",
      "done\n",
      "writing filled daily file ../data/gauge//maun_dly_filled.csv\n",
      "done\n",
      "generating monthly data...\n",
      "done\n",
      "writing monthly file ../data/gauge//maun_mon.csv\n",
      "done\n",
      "\n",
      "\n",
      "processing mohembo\n",
      "reading ../data/gauge//mohembo_dly_combined.csv\n",
      "done\n",
      "filtering data\n",
      "done\n",
      "writing filled daily file ../data/gauge//mohembo_dly_filled.csv\n",
      "done\n",
      "generating monthly data...\n",
      "done\n",
      "writing monthly file ../data/gauge//mohembo_mon.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "gauges=[\"toteng\",\"maun\",\"mohembo\"]\n",
    "datadir=\"../data/gauge/\"\n",
    "fy,ly=\"2007\",\"2012\" #years for which data will be plotted for inspection if verbose=True\n",
    "verbose=False\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "#be careful editing below this line\n",
    "for gauge in gauges:\n",
    "    print(\"\\n\\nprocessing {}\".format(gauge))\n",
    "    \n",
    "    inputfilepath=datadir+\"/\"+gauge+\"_dly_combined.csv\"\n",
    "    filledfilepath=datadir+\"/\"+gauge+\"_dly_filled.csv\"\n",
    "    monthlyfilepath=datadir+\"/\"+gauge+\"_mon.csv\"\n",
    "    print(\"reading {}\".format(inputfilepath))\n",
    "    data=pd.read_csv(inputfilepath, index_col=0, parse_dates=True)\n",
    "    print(\"done\")\n",
    "    #filtering data\n",
    "    #this is to prepare daily time series for converting to monthly while \n",
    "    # distinguishing what we know from what we don't know\n",
    "    #this basically creates gaps in the time series created by interpolation function \n",
    "    #in periods that should not be interpolated across\n",
    "    # one has to critically evaluate obs data\n",
    "    print(\"filtering data\")\n",
    "    datafilled=data.resample(\"D\").mean().interpolate(\"time\",order=3)\n",
    "    if gauge==\"maun\":\n",
    "        datafilled['water level'][\"1984-05-14\":\"1987-09-28\"][:]=np.nan\n",
    "        datafilled['water level'][\"1987-11-07\":\"1988-07-14\"][:]=np.nan\n",
    "        datafilled['water level'][\"1995-01-20\":\"1997-09-18\"][:]=np.nan\n",
    "        datafilled['water level'][\"1997-10-10\":\"1998-06-24\"][:]=np.nan\n",
    "        datafilled['water level'][\"2006-01-21\":\"2013-11-12\"][:]=np.nan\n",
    "    if gauge==\"toteng\":    \n",
    "        datafilled[:][\"1971-11-15\":\"1974-04-25\"][:]=np.nan\n",
    "        datafilled['discharge'][\"1978-09-29\":\"1980-10-01\"][:]=np.nan\n",
    "        datafilled['discharge'][\"1980-11-14\":\"1984-07-06\"][:]=np.nan\n",
    "        datafilled['water level'][\"1981-01-01\":\"1981-09-03\"][:]=np.nan\n",
    "        datafilled['water level'][\"1982-01-10\":\"1982-10-01\"][:]=np.nan\n",
    "        datafilled['water level'][\"1982-10-25\":\"1984-07-06\"][:]=np.nan\n",
    "        datafilled[:][\"1984-12-31\":\"1986-07-19\"][:]=np.nan\n",
    "        datafilled[:][\"1986-09-24\":\"1988-08-28\"][:]=np.nan\n",
    "        datafilled['water level'][\"1989-12-23\":\"1992-07-13\"][:]=np.nan\n",
    "        datafilled['water level'][\"1988-10-13\":\"1989-06-22\"][:]=np.nan\n",
    "        datafilled['water level'][\"1992-10-29\":\"1993-06-01\"][:]=np.nan\n",
    "        datafilled['water level'][\"2000-11-29\":\"2001-10-01\"][:]=np.nan\n",
    "        datafilled['water level'][\"2001-11-29\":\"2002-06-01\"][:]=np.nan\n",
    "        datafilled['water level'][\"2005-01-17\":\"2005-07-15\"][:]=np.nan\n",
    "        datafilled['water level'][\"2005-11-10\":\"2006-08-10\"][:]=np.nan\n",
    "        datafilled['water level'][\"2007-01-18\":\"2007-06-19\"][:]=np.nan\n",
    "        datafilled['water level'][\"2007-12-30\":\"2008-09-09\"][:]=np.nan\n",
    "        datafilled['water level'][\"2009-01-01\":\"2009-06-01\"][:]=np.nan\n",
    "        datafilled[:][\"2013-07-23\":\"2014-05-06\"][:]=np.nan\n",
    "        datafilled['water level'][\"2014-01-01\":\"2020-12-31\"][:]=np.nan\n",
    "        datafilled[:][\"2018-01-19\":\"2018-07-14\"][:]=np.nan\n",
    "        datafilled[:][\"2018-08-22\":\"2020-12-31\"][:]=np.nan\n",
    "        datafilled[:][\"2014-11-07\":\"2015-06-11\"][:]=np.nan\n",
    "    if gauge==\"mohembo\":    \n",
    "        datafilled['water level'][\"2007-09-11\":\"2008-09-30\"][:]=np.nan\n",
    "        datafilled['water level'][\"2009-05-01\":\"2011-10-01\"][:]=np.nan\n",
    "    print(\"done\")\n",
    "    \n",
    "    if verbose:\n",
    "        fig=plt.figure(figsize=(15,6))\n",
    "        pl=fig.add_subplot(2,1,1)\n",
    "        style=\"o-\"    \n",
    "        pl.plot(datafilled['discharge'][fy:ly], style, label=\"Q daily filled\", markersize=5)\n",
    "        pl.plot(data['discharge'][fy:ly], style, label=\"Q daily raw\", markersize=2)\n",
    "\n",
    "        pl.set_ylabel(\"discharge [m3/s]\")\n",
    "        plt.legend()\n",
    "\n",
    "        pl=fig.add_subplot(2,1,2)\n",
    "        style=\"o-\"\n",
    "        pl.plot(datafilled['water level'][fy:ly], style, label=\"WL daily filled\", markersize=5)\n",
    "        pl.plot(data['water level'][fy:ly], style, label=\"WL daily raw\", markersize=2)\n",
    "        pl.set_ylabel(\"water level [m]\")\n",
    "        plt.suptitle(gauge)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"writing filled daily file {}\".format(filledfilepath))\n",
    "    np.round(datafilled, 2).to_csv(filledfilepath, date_format=\"%d-%m-%Y\")\n",
    "    print(\"done\")\n",
    "\n",
    "    print(\"generating monthly data...\")\n",
    "    datamon=np.round(datafilled.resample(\"M\").mean(),2)\n",
    "    datamon['discharge']=np.round(np.round(datafilled['discharge'].resample(\"M\").sum(),2)*86400/1000000,2)\n",
    "    #filtering out nans\n",
    "    validmon=np.invert(np.isnan(datafilled)).resample(\"M\").sum()\n",
    "    datamon[validmon<10]=np.nan\n",
    "    print(\"done\")\n",
    "\n",
    "    if verbose:\n",
    "        fig=plt.figure(figsize=(15,6))\n",
    "        pl=fig.add_subplot(2,1,1)\n",
    "        pl.plot(datamon['discharge'][fy:ly], \"-\", label=\"Q monthly\")\n",
    "        pl.set_ylabel(\"discharge [Mm3]\")\n",
    "        plt.legend()\n",
    "\n",
    "        pl=fig.add_subplot(2,1,2)\n",
    "        pl.plot(datamon['water level'][fy:ly], label=\"WL monthly\")\n",
    "        pl.set_ylabel(\"water level [m]\")\n",
    "        plt.legend()\n",
    "        plt.suptitle(gauge)\n",
    "        plt.show()\n",
    "\n",
    "    print(\"writing monthly file {}\".format(monthlyfilepath))\n",
    "    datamon.to_csv(monthlyfilepath)\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016936ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
