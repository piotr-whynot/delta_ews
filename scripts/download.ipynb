{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e155dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from osgeo import gdal\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035911e",
   "metadata": {},
   "source": [
    "# Downloading and preparing MODIS inundation maps\n",
    "this loads tif files for individual days, merges them and converts to netcdf format for easier ingestion in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f88301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModisDates(_startDate, _endDate):\n",
    "    #returns pandas datetimeindex\n",
    "    _dataJDays=range(1,365,8)\n",
    "    _allDays=pd.date_range(_startDate,_endDate,freq=\"D\")\n",
    "    return _allDays[np.in1d([x.timetuple().tm_yday for x in _allDays],_dataJDays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6574c55c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking data between 2022-08-23 06:51:25.558584 and 2022-09-17 06:51:25.558584\n",
      "checking if https://www.okavangodata.ub.bw is up\n",
      "Error Connecting: HTTPSConnectionPool(host='www.okavangodata.ub.bw', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f40415510a0>, 'Connection to www.okavangodata.ub.bw timed out. (connect timeout=30)'))\n",
      "server https://www.okavangodata.ub.bw is down.\n"
     ]
    }
   ],
   "source": [
    "#endDate should be either date as YYYY-MM-DD or \"today\"\n",
    "endDate=\"2020-02-01\"\n",
    "endDate=\"today\"\n",
    "\n",
    "#either date as YYYY-MM-DD or number of days before the endDate\n",
    "startDate=\"2020-01-01\"\n",
    "startDate=25\n",
    "\n",
    "remoteserver=\"https://www.okavangodata.ub.bw\"\n",
    "remotedir=\"{}/modis/\".format(remoteserver)\n",
    "\n",
    "\n",
    "datadir=\"../data/flood/\"\n",
    "tifdir=datadir+\"/tif/\"\n",
    "filenamepattern=\"A{}.flood.tif\"\n",
    "mergedfile=\"flood_modis_merged.nc\"\n",
    "\n",
    "verbose=True\n",
    "\n",
    "##########################################################################################################\n",
    "try:\n",
    "    endDate=datetime.datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "except:\n",
    "    endDate=datetime.datetime.today() #today\n",
    "\n",
    "try:\n",
    "    startDate=datetime.datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "except:\n",
    "    if not isinstance(startDate,int):\n",
    "        startDate=30\n",
    "    startDate=endDate - datetime.timedelta(startDate)\n",
    "\n",
    "if endDate<=startDate:\n",
    "    print(\"startDate has to be before endDate. You got: \\nstartDate:{} \\nendDate:{}. \\nExiting...\".format(startDate,endDate))\n",
    "    sys.exit()\n",
    "\n",
    "print(\"checking data between {} and {}\".format(startDate,endDate))\n",
    "\n",
    "dates2check=getModisDates(startDate,endDate)\n",
    "if len(dates2check)==0:\n",
    "    print(\"There are no data dates between startDate and endDate. You got: \\nstartDate:{} \\nendDate:{}. \\nExiting...\".format(startDate,endDate))\n",
    "    sys.exit()\n",
    "    \n",
    "count=0\n",
    "update=False\n",
    "\n",
    "#checking if server is up\n",
    "print(\"checking if {} is up\".format(remoteserver))\n",
    "cont=False\n",
    "try:\n",
    "    response=requests.head(remoteserver,timeout=30)\n",
    "    response.raise_for_status()\n",
    "    cont=True\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print (\"Http Error:\",errh)\n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print (\"Error Connecting:\",errc)\n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print (\"Timeout Error:\",errt)\n",
    "except requests.exceptions.RequestException as err:\n",
    "    print (\"OOps: Something Else\",err)\n",
    "    \n",
    "if cont:\n",
    "    #server is up\n",
    "    for date in dates2check:\n",
    "        file=filenamepattern.format(date.strftime(\"%Y%j\"))\n",
    "        filepath=tifdir+\"/\"+file\n",
    "        if os.path.exists(filepath):\n",
    "            if verbose:\n",
    "                print(\"file {} exists locally. skipping...\".format(file))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Downloading {} from {} into {}\".format(file,remotedir,tifdir))\n",
    "            url=remotedir+\"/\"+file\n",
    "            response=requests.head(url)\n",
    "            if response.status_code!=200:\n",
    "                if verbose:\n",
    "                    print(\"file {} on {} does not exist. skipping...\".format(file,remotedir))\n",
    "            else:\n",
    "                with requests.get(url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192): \n",
    "                            f.write(chunk)\n",
    "\n",
    "                localfilesize=os.stat(filepath)[6]\n",
    "                remotefilesize=int(response.headers['content-length'])\n",
    "                if verbose:\n",
    "                    print (\"downloaded file size: {}\".format(localfilesize))\n",
    "                    print (\"expected file size: {}\".format(remotefilesize))\n",
    "                if localfilesize != remotefilesize:\n",
    "                    if verbose:\n",
    "                        print(\"something went wrong. removing downloaded file\")\n",
    "                    os.rename(filepath, filepath+\".fail\")\n",
    "                else:\n",
    "                    count=count+1\n",
    "                    if verbose:\n",
    "                        print(\"download successful\")\n",
    "else:\n",
    "    print(\"server {} is down.\".format(remoteserver))\n",
    "    update=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98a8710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 new files. Updating merged file\n",
      "processing files in ../data/flood//tif/\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "Found 704 files covering period between 2000-04-30 and 2022-07-12\n",
      "writing netcdf file: ../data/flood//flood_modis_merged.nc\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "if count>0 or update:\n",
    "    print(\"Downloaded {} new files. Updating merged file\".format(count))\n",
    "\n",
    "    files=glob.glob(tifdir+\"/*flood.tif\")\n",
    "\n",
    "    print(\"processing files in {}\".format(tifdir))\n",
    "    i=0\n",
    "    for file in np.sort(files):\n",
    "        i=i+1\n",
    "        if i%100==0:\n",
    "            print(i)\n",
    "        filedatestr=os.path.basename(file)[1:8]\n",
    "        filedate=datetime.datetime.strptime(filedatestr, '%Y%j')\n",
    "        im=Image.open(file)\n",
    "        data=np.array(im)\n",
    "        if i==1:\n",
    "            dates=[filedate]\n",
    "            alldata=data[:,:,0:1]\n",
    "            ds = gdal.Open(file)\n",
    "            nx = ds.RasterXSize\n",
    "            ny = ds.RasterYSize\n",
    "            xmin,xsize,tmp,ymin,tmp,ysize=ds.GetGeoTransform()\n",
    "            lons=np.linspace(xmin,xmin+xsize*nx,num=nx)\n",
    "            lats=np.linspace(ymin,ymin+ysize*ny,num=ny)\n",
    "        else:\n",
    "            dates=dates+[filedate]\n",
    "            alldata=np.append(alldata,data[:,:,0:1],2)\n",
    "        im.close()\n",
    "    firstdatestr,lastdatestr=datetime.datetime.strftime(dates[0],\"%Y-%m-%d\"),datetime.datetime.strftime(dates[-1],\"%Y-%m-%d\")\n",
    "\n",
    "    print(\"Found {} files covering period between {} and {}\".format(len(dates),firstdatestr,lastdatestr))\n",
    "\n",
    "    #ordering axes in the array so that is has the standard time,lat,lon\n",
    "    alldata=alldata.swapaxes(0,2)\n",
    "    alldata=alldata.swapaxes(1,2)\n",
    "\n",
    "    #recoding\n",
    "    #tif files contain only 3 (0 for flooded, 255 for not flooded, and 127 for unclassified)\n",
    "    # this is recoded here to 1 for flooded,0 for not flooded and np.nan for unclassified\n",
    "    alldata[alldata==0]=1\n",
    "    alldata[alldata==255]=0\n",
    "    alldata[alldata==127]=2\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        {\"flood\": ((\"time\", \"latitude\",\"longitude\"), alldata)},\n",
    "        coords={\n",
    "            \"longitude\": lons,\n",
    "            \"latitude\": lats,\n",
    "            \"time\": dates,\n",
    "        },\n",
    "    )\n",
    "    ds[\"latitude\"].attrs = {\"units\":\"degrees_north\",'standard_name':\"latitude\",'axis':\"Y\"}\n",
    "    ds[\"longitude\"].attrs = {\"units\":\"degrees_east\",'standard_name':\"longitude\",'axis':\"X\"}\n",
    "\n",
    "    #flood=flood.rio.write_crs(\"epsg:4326\")\n",
    "\n",
    "    mergedfilepath=datadir+\"/\"+mergedfile\n",
    "\n",
    "    print(\"writing netcdf file: {}\".format(mergedfilepath))\n",
    "    ds.to_netcdf(mergedfilepath)\n",
    "    print(\"finished\")\n",
    "else:\n",
    "    print(\"No new files downloaded. Skipping updating merged file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381d497",
   "metadata": {},
   "source": [
    "# Downloading and preparing CHIRPS rainfall data\n",
    "this loads tif files for individual days, merges them and converts to netcdf format for easier ingestion in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "962126b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking data between 2022-08-23 07:41:41.073665 and 2022-09-17 07:41:41.073665\n"
     ]
    }
   ],
   "source": [
    "#endDate should be either date as YYYY-MM-DD or \"today\"\n",
    "endDate=\"2020-02-01\"\n",
    "endDate=\"today\"\n",
    "\n",
    "#either date as YYYY-MM-DD or number of days before the endDate\n",
    "startDate=\"2020-01-01\"\n",
    "startDate=25\n",
    "\n",
    "\n",
    "remoteserver=\"https://data.chc.ucsb.edu\"\n",
    "remotedir=\"{}/products/CHIRPS-2.0/africa_daily/tifs/p25/\".format(remoteserver)\n",
    "prelimremotedir=\"{}/products/CHIRPS-2.0/prelim/global_daily/tifs/p25/\".format(remoteserver)\n",
    "\n",
    "\n",
    "datadir=\"../data/rainfall/\"\n",
    "tifdir=datadir+\"/chirps-v2.0/tifs/\"\n",
    "filenamepattern=\"chirps-v2.0.{}.tif\"\n",
    "prelimtifdir=datadir+\"/chirps-v2.0-prelim/tifs/\"\n",
    "prelimfilenamepattern=\"chirps-v2.0.{}.tif\"\n",
    "\n",
    "mergedfile=\"pr_chirps_merged.nc\"\n",
    "\n",
    "\n",
    "verbose=True\n",
    "\n",
    "##########################################################################################################\n",
    "try:\n",
    "    endDate=datetime.datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "except:\n",
    "    endDate=datetime.datetime.today() #today\n",
    "\n",
    "try:\n",
    "    startDate=datetime.datetime.strptime(startDate, \"%Y-%m-%d\")\n",
    "except:\n",
    "    if not isinstance(startDate,int):\n",
    "        #this should not be lower than 50 - this is because chirps gets updated in monthly batches,\n",
    "        # the entire month gets updates on the 16th of the next month, so on the 16th we need to check for\n",
    "        # and update data since the beginnng of the previous month\n",
    "        startDate=60 \n",
    "    startDate=endDate - datetime.timedelta(startDate)\n",
    "\n",
    "if endDate<=startDate:\n",
    "    print(\"startDate has to be before endDate. You got: \\nstartDate:{} \\nendDate:{}. \\nExiting...\".format(startDate,endDate))\n",
    "    sys.exit()\n",
    "\n",
    "print(\"checking data between {} and {}\".format(startDate,endDate))\n",
    "dates2check=pd.date_range(startDate.strftime(\"%Y-%m-%d\"),endDate.strftime(\"%Y-%m-%d\"), freq=\"D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3140d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(_url,_localfilepath, verbose=True):\n",
    "    response=requests.head(_url)\n",
    "    if response.status_code!=200:\n",
    "        if verbose:\n",
    "            print(\" {} does not exist. skipping...\".format(_url))\n",
    "        return False\n",
    "    else:\n",
    "        with requests.get(_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(_localfilepath, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192): \n",
    "                    f.write(chunk)\n",
    "\n",
    "        localfilesize=os.stat(_localfilepath)[6]\n",
    "        remotefilesize=int(response.headers['content-length'])\n",
    "        if verbose:\n",
    "            print (\"downloaded file size: {}\".format(localfilesize))\n",
    "            print (\"expected file size: {}\".format(remotefilesize))\n",
    "        if localfilesize != remotefilesize:\n",
    "            if verbose:\n",
    "                print(\"something went wrong. removing downloaded file\")\n",
    "            os.rename(_localfilepath, _localfilepath+\".fail\")\n",
    "            return False\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"download successful\")\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "803fe095",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking if https://data.chc.ucsb.edu is up\n",
      "file chirps-v2.0.2022.08.23.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.24.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.25.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.26.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.27.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.28.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.29.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.30.tif exists locally. skipping...\n",
      "file chirps-v2.0.2022.08.31.tif exists locally. skipping...\n",
      "Downloading chirps-v2.0.2022.09.01.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.01.tif does not exist. skipping...\n",
      "file chirps-v2.0.2022.09.01.tif exists locally. skipping...\n",
      "Downloading chirps-v2.0.2022.09.02.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.02.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.02.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.03.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.03.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.03.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.04.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.04.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.04.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.05.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.05.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.05.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.06.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.06.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.06.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.07.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.07.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.07.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.08.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.08.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.08.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.09.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.09.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.09.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.10.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.10.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.10.tif\n",
      "downloaded file size: 2307820\n",
      "expected file size: 2307820\n",
      "download successful\n",
      "Downloading chirps-v2.0.2022.09.11.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.11.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.11.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.11.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.12.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.12.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.12.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.12.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.13.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.13.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.13.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.13.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.14.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.14.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.14.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.14.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.15.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.15.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.15.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.15.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.16.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.16.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.16.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.16.tif does not exist. skipping...\n",
      "Downloading chirps-v2.0.2022.09.17.tif from https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25/ into ../data/rainfall//chirps-v2.0/tifs/\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p25//2022/chirps-v2.0.2022.09.17.tif does not exist. skipping...\n",
      "Downloading https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//chirps-v2.0.2022.09.17.tif\n",
      " https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/tifs/p25//2022/chirps-v2.0.2022.09.17.tif does not exist. skipping...\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "update=False\n",
    "\n",
    "#checking if server is up\n",
    "print(\"checking if {} is up\".format(remoteserver))\n",
    "cont=False\n",
    "try:\n",
    "    response=requests.head(remoteserver)\n",
    "    response.raise_for_status()\n",
    "    cont=True\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print (\"Http Error:\",errh)\n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print (\"Error Connecting:\",errc)\n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print (\"Timeout Error:\",errt)\n",
    "except requests.exceptions.RequestException as err:\n",
    "    print (\"Oops: Something Else\",err)\n",
    "    \n",
    "if cont:\n",
    "    #server is up\n",
    "    for date in dates2check:\n",
    "        file=filenamepattern.format(date.strftime(\"%Y.%m.%d\"))\n",
    "        localfilepath=tifdir+\"/\"+file\n",
    "        if os.path.exists(localfilepath):\n",
    "            if verbose:\n",
    "                print(\"file {} exists locally. skipping...\".format(file))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Downloading {} from {} into {}\".format(file,remotedir,tifdir))\n",
    "            url=\"{}/{}/{}\".format(remotedir,date.strftime(\"%Y\"),file)\n",
    "            response=download_file(url,localfilepath)\n",
    "            #downloading prelim file\n",
    "            if response==False:\n",
    "                prelimfile=prelimfilenamepattern.format(date.strftime(\"%Y.%m.%d\"))\n",
    "                prelimlocalfilepath=prelimtifdir+\"/\"+prelimfile\n",
    "                if os.path.exists(prelimlocalfilepath):\n",
    "                    if verbose:\n",
    "                        print(\"file {} exists locally. skipping...\".format(prelimfile))\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(\"Downloading {}/{}\".format(prelimremotedir,prelimfile))\n",
    "                    url=\"{}/{}/{}\".format(prelimremotedir,date.strftime(\"%Y\"),prelimfile)\n",
    "                    response=download_file(url,prelimlocalfilepath)\n",
    "#                    sys.exit()\n",
    "else:\n",
    "    print(\"server {} is down.\".format(remoteserver))\n",
    "    update=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475eb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
